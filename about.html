<!DOCTYPE html><html><head><meta name="viewport" content="width=device-width"/><meta charSet="utf-8"/><link rel="shortcut icon" href="/NViz/images/favicon.ico"/><title>NViz | About</title><meta name="next-head-count" content="4"/><link rel="preload" href="/NViz/_next/static/css/ef98e6292290eae3.css" as="style"/><link rel="stylesheet" href="/NViz/_next/static/css/ef98e6292290eae3.css" data-n-g=""/><noscript data-n-css=""></noscript><script defer="" nomodule="" src="/NViz/_next/static/chunks/polyfills-5cd94c89d3acac5f.js"></script><script src="/NViz/_next/static/chunks/webpack-49b4013c6c6ba8bc.js" defer=""></script><script src="/NViz/_next/static/chunks/framework-81eee04dc9c81fd8.js" defer=""></script><script src="/NViz/_next/static/chunks/main-e0b21535397f1d67.js" defer=""></script><script src="/NViz/_next/static/chunks/pages/_app-c5b5d076e7472c2d.js" defer=""></script><script src="/NViz/_next/static/chunks/pages/about-57b02c9d76cd9811.js" defer=""></script><script src="/NViz/_next/static/kZ90l0jaGfOxRLjTIG7z_/_buildManifest.js" defer=""></script><script src="/NViz/_next/static/kZ90l0jaGfOxRLjTIG7z_/_ssgManifest.js" defer=""></script><script src="/NViz/_next/static/kZ90l0jaGfOxRLjTIG7z_/_middlewareManifest.js" defer=""></script></head><body><div id="__next" data-reactroot=""><div class="site flex flex-col h-full w-full bg-gray-900 font-vietnam"><div class="flex flex-row w-full bg-gray-900 h-20 items-center border-b-2 border-teal-900"><div class="ml-6 mr-6"><a class="flex flex-row text-white text-2xl items-center hover:text-white" href="/NViz"><img src="/NViz/images/favicon.ico" class="h-10 mr-4"/>NViz</a></div><div class="items-center w-1/3"><a class="text-white text-base hover:text-teal-400 hover:cursor-pointer mr-4" href="/NViz/about">About</a><a class="text-white text-base hover:text-teal-400 hover:cursor-pointer" href="/NViz/format">File Format</a></div><div class="flex flex-row ml-auto w-1/4 h-full items-center justify-end"><div class="flex flex-row w-1/2 h-1/3 justify-end mr-4"><a class="flex flex-row justify-end" target="_blank" href="https://github.com/ahluwalij/NViz"><p class="flex text-center items-center justify-center mr-4 text-gray-500 cursor-default">Made by Jasdeep Ahluwalia</p><img class="h-full cursor-pointer" src="/NViz/images/github.svg"/></a></div></div></div><div class="flex w-full h-full"><div class="flex flex-col mt-24 text-white justify-center text-center items-center"><h1 class="text-4xl underline mb-4">About NViz</h1><div class="w-1/2 h-1/2"><img src="/NViz/images/network.png"/></div><div class="w-3/5 h-full mb-12"><div id="about" class="mb-8"><h2 class="text-2xl text-teal-500">What is NViz?</h2><p class="text-lg">NViz is an online visualization platform for both the structure and training of <a href="https://en.wikipedia.org/wiki/Multilayer_perceptron" target="_blank">multiplayer perceptron</a> (MLP) <a href="https://en.wikipedia.org/wiki/Feedforward_neural_network" target="_blank">feed-forward neural networks.</a></p></div><div id="use" class="mb-8"><h2 class="text-2xl text-teal-500">What can I use it for?</h2><p class="text-lg">You can use NViz for training, visualizing, and experimenting with a variety of different feed-forward neural network architectures on your own training datasets. Simply provide a dataset in the <a target="_blank" href="/NViz/format">correct format</a>, adjust the settings as you see fit, and press train to see your neural network in action! You can provide an input file to test your model&#x27;s predictions, or you can download the model&#x27;s weights for your own use.</p></div><div id="made" class="mb-8"><h2 class="text-2xl text-teal-500">What is it made with?</h2><p class="text-lg">NViz is made with <a target="_blank" href="https://nextjs.org/">Next.js</a> and <a href="https://reactjs.org/" target="_blank">React</a> with <a href="https://tailwindcss.com/" target="_blank">Tailwind</a> for styling. It uses <a href="https://www.cplusplus.com/" target="_blank">C++</a> and <a href="https://webassembly.org/" target="_blank">WebAssembly</a> to train your model from directly within your browser at lightning-fast speeds!</p></div><div id="open-source" class="mb-8"><h2 class="text-2xl text-teal-500">Is it open source?</h2><p class="text-lg">Absolutely! NViz is entirely open-source and available on <a href="https://github.com/ahluwalij/NViz">GitHub. </a>If you enjoy NViz and find it helpful, consider leaving a star on the repository! If not, please feel free to file an issue and describe how you feel it could be improved. </p></div><div id="datasets" class="mb-8"><h2 class="text-2xl text-teal-500">I&#x27;d like to try NViz, but I don&#x27;t have a dataset...</h2><p class="text-lg">NViz was created to help people develop a better understanding of the structure and training of neural networks on their own datasets, but if you just want to experiment with the site and explore its capabilities, that&#x27;s perfectly fine! A number of feasible datasets are readily available on the <a href="https://github.com/ahluwalij/NViz/tree/master/datasets" target="_blank">GitHub repository</a> for you to use. If you would like to train on your own dataset, follow the <a target="_blank" href="/NViz/format">format guide</a> for structuring your data files.</p></div><div id="limits" class="mb-8"><h2 class="text-2xl text-teal-500">What are its limitations?</h2><p class="text-lg">As mentioned, NViz can visualize and train multilayer perceptron feed-forward neural networks. While fairly general, these aren&#x27;t as robust or versatile as other, more complex models such as <a href="https://en.wikipedia.org/wiki/Recurrent_neural_network" target="_blank">recurrent neural networks</a> (RNNs). NViz also allows a maximum of 1000 nodes in any individual layer to ease the load on your browser. Additionally, all models trained on NViz make use of the <a href="https://en.wikipedia.org/wiki/Logistic_function" target="_blank">Sigmoid</a> <a href="https://en.wikipedia.org/wiki/Activation_function" target="_blank">activation function</a> at hidden layers. Sigmoid outputs are scaled from 0 to 1, so training data must have accordingly normalized outputs. Other activation functions such as ReLU and tanh may be better suited depending on the purpose of the neural network. In the future, NViz will support the selection of different activation functions based on model purpose. </p></div></div><div class="w-3/5 h-full"><h1 class="text-4xl underline mb-8">Technical Information</h1><div id="bias" class="mb-8"><h2 class="text-2xl text-teal-500">What is the extra <span class="text-yellow-300">yellow</span> node in the input layer?</h2><p class="text-lg">The extra node in the input layer is called a <a href="https://www.pico.net/kb/the-role-of-bias-in-neural-networks/" target="_blank">bias</a>. Consider it an extra, constant input that acts like a battery providing continuous power to your network.</p></div><div id="speed" class="mb-8"><h2 class="text-2xl text-teal-500">What is training speed?</h2><p class="text-lg">While JavaScript&#x27;s event loop is considered non-blocking, it can in fact be blocked by tasks such as infinite while-loops, which is essentially what happens when you press &quot;Train&quot;. To prevent event-loop blocking during this loop, after each training batch there is a 4 millisecond yield during which the event loop can process tasks such as handling a click on the &quot;Stop training&quot; button. The &quot;training speed&quot; setting is, effectively, the number of training pairs that are processed during each batch before the loop yields. The higher the &quot;training speed&quot;, the more training pairs are processed during each batch. However, somewhat counterintuitively, a lower &quot;training speed&quot; setting may sometimes actually result in faster training, due to the nature of resource and load management. Setting the training speed too high may bottleneck the loop and result in actually slower training or even an unresponsive UI. Adjust training speed before and during training for best results.</p></div><div id="inaccurate" class="mb-8"><h2 class="text-2xl text-teal-500">I&#x27;m not getting the results I want...</h2><p class="text-lg">Neural network model accuracy is highly dependant on features such as network architecture, training rate, and the quality and quantity of its training dataset. Use NViz as a platform to experiment with different architectures and settings! Perhaps refine your training dataset or reduce its size to prevent redundancy and increase the rate of training (effectively raising <a href="https://deepai.org/machine-learning-glossary-and-terms/epoch" target="_blank">epochs</a>/second). If no amount of experimentation is working, it might be the case that a simple MLP feed-forward network simply does not have the capacity to solve your problem, or an online platform may not be performant enough to quickly train on your dataset. Consider programming your own model from scratch using popular libraries like <a href="https://pytorch.org/" target="_blank">Pytorch</a> or <a href="https://www.tensorflow.org/" target="_blank">Tensorflow.</a></p></div></div></div></div></div></div><script id="__NEXT_DATA__" type="application/json">{"props":{"pageProps":{}},"page":"/about","query":{},"buildId":"kZ90l0jaGfOxRLjTIG7z_","assetPrefix":"/NViz","nextExport":true,"autoExport":true,"isFallback":false,"scriptLoader":[]}</script></body></html>